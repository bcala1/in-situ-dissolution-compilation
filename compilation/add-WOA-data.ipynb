{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0520b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "import xarray as xr\n",
    "import gsw\n",
    "\n",
    "with open('../woa18/path-to-woa18-files.txt') as f:\n",
    "    path_woa = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0022240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not using decadal data anymore, just the decav or all\n",
    "decades = {}\n",
    "for y in np.arange(1965,1975,1): decades[y] = '6574'\n",
    "for y in np.arange(1975,1985,1): decades[y] = '7584'\n",
    "for y in np.arange(1985,1995,1): decades[y] = '8594'\n",
    "for y in np.arange(1995,2005,1): decades[y] = '95A4'  \n",
    "for y in np.arange(2005,2019,1): decades[y] = 'A5B7' \n",
    "\n",
    "seasons = {}\n",
    "for m in [1,2,3]: seasons[m] = '13'\n",
    "for m in [4,5,6]: seasons[m] = '14'\n",
    "for m in [7,8,9]: seasons[m] = '15'\n",
    "for m in [10,11,12]: seasons[m] = '16'\n",
    "    \n",
    "    \n",
    "depths = np.array([0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,125,150,175,200,225,250,275,300,325,350,\n",
    "       375,400,425,450,475,500,550,600,650,700,750,800,850,900,950,1000,1050,1100,1150,1200,1250,1300,1350,1400,\n",
    "       1450,1500,1550,1600,1650,1700,1750,1800,1850,1900,1950,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,\n",
    "       3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,\n",
    "       5000,5100,5200,5300,5400,5500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08533830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load compiled dissolution data\n",
    "df = pd.read_csv(\"data/in_situ_rates_compiled.csv\")\n",
    "#add a new column with pressure to dataset, this is later needed for the CANYON-B calculation\n",
    "df[\"Pressure\"] = gsw.p_from_z(np.array(df[\"Depth\"]*(-1)), np.array(df[\"Latitude\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e64fd4",
   "metadata": {},
   "source": [
    "### import WOA data\n",
    "#### Data availability:\n",
    "- temperature (t): \n",
    "    - decadal data or decav\n",
    "    - 0 - 5500 m for annual and seasonal\n",
    "- salinity (s): \n",
    "    - decadal data or decav\n",
    "    - 0 - 5500 m for annual and seasonal\n",
    "- oxygen (o): \n",
    "    - all years\n",
    "    - 0 - 5500 m for annual, 0 - 1500 m for seasonal (57 levels)\n",
    "- phosphate (p): \n",
    "    - all years\n",
    "    - 0 - 5500 m for annual, 0 - 800 m for seasonal (43 levels)\n",
    "- silicate (i): \n",
    "    - all years\n",
    "    - 0 - 5500 m for annual, 0 - 800 m for seasonal (43 levels)\n",
    "    \n",
    "#### how data is chosen\n",
    "- in general, the upper 1500 m with seasonal data and below the annual average\n",
    "- for p and i, the upper 800 m is seasonal data and below the annual average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd9028",
   "metadata": {},
   "source": [
    "## define functions to import correct data and interpolate\n",
    "- for the climatology:\n",
    "    - upper 1500 m (800 m for nuts) is seasonal (if known) \n",
    "    - below annual averages\n",
    "- for standard deviation:\n",
    "    - if possible, same as the climatology\n",
    "    - but often times there are not enough measurements that make up the standard deviation (should be at least 5), then I just take the annual data\n",
    "- special case doxy sd:\n",
    "    - there are really not many measurements, often at the site of the dissolution experiment none so sd is not available there or not meaningful\n",
    "    - I therefore take average SD from grid points in the surrounding area that have enough measurements\n",
    "        - grid points are considered if they have at least 5 measurements at 1500 m depth (assumption is that above that there are at least that number of measurements for most depths)\n",
    "        - a considered grid point is only 'participating' in the average, if it also has >= 5 measurements at that certain depth\n",
    "    - nan values are forward filled\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90943b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_var_an(var, lat, lon, seas):\n",
    "    # import annual (y) and seasonal (s) data\n",
    "    try:\n",
    "        if (var == 't') or (var == 's'):\n",
    "            var_y = xr.open_dataset(path_woa+\"woa18_decav_\"+var+\"00_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "            var_s = xr.open_dataset(path_woa+\"woa18_decav_\"+var+seas+\"_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "        else:\n",
    "            var_y = xr.open_dataset(path_woa+\"woa18_all_\"+var+\"00_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "            var_s = xr.open_dataset(path_woa+\"woa18_all_\"+var+seas+\"_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "    except:\n",
    "        print(var, 'file is missing')\n",
    "\n",
    "    # find location of measurement site:\n",
    "    var_y_loc = var_y.sel(lat=lat, lon=lon, method=\"nearest\", tolerance=0.5)\n",
    "    var_s_loc = var_s.sel(lat=lat, lon=lon, method=\"nearest\", tolerance=0.5)\n",
    "    \n",
    "    # get arrays (annual average (an), standard deviation (sd), number of observations (dd))\n",
    "    # upper 800 (43 levels) from seasonal (if season not known, then it's just the annual data anyway)\n",
    "    # everything below is from annual data\n",
    "    if (var == 'p') or (var == 'i'):\n",
    "        var_an = np.append(var_s_loc[var+'_an'].values[0:43], var_y_loc[var+'_an'].values[43:])\n",
    "    else:\n",
    "        var_an = np.append(var_s_loc[var+'_an'].values[0:57], var_y_loc[var+'_an'].values[57:])\n",
    "        \n",
    "    return var_an\n",
    "\n",
    "\n",
    "\n",
    "def import_var_sd(var, lat, lon, seas):\n",
    "    if (var == 'p') or (var == 'i'):\n",
    "        print(\"DON'T DO PHOSPHATE OR SILICATE, RIGHT NOW THIS DOES NOT WORK AND THE DEPTHS DON'T LINE UP\")\n",
    "    \n",
    "    # import annual (y) and seasonal (s) data\n",
    "    try:\n",
    "        if (var == 't') or (var == 's'):\n",
    "            var_y = xr.open_dataset(path_woa+\"woa18_decav_\"+var+\"00_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "            var_s = xr.open_dataset(path_woa+\"woa18_decav_\"+var+seas+\"_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "        else:\n",
    "            var_y = xr.open_dataset(path_woa+\"woa18_all_\"+var+\"00_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "            var_s = xr.open_dataset(path_woa+\"woa18_all_\"+var+seas+\"_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "    except:\n",
    "        print(var, 'file is missing')\n",
    "\n",
    "    # find location of measurement site:\n",
    "    var_y_loc = var_y.sel(lat=lat, lon=lon, method=\"nearest\", tolerance=0.5)\n",
    "    var_s_loc = var_s.sel(lat=lat, lon=lon, method=\"nearest\", tolerance=0.5)\n",
    "\n",
    "\n",
    "    # if for the seasonal data all dd are above 5, we take the sd from there\n",
    "    if all(i >= 5 for i in var_s_loc[var+'_dd'].values[0:57]):\n",
    "        print('sd',var, 'from seasonal + annual data')\n",
    "        var_sd = np.append(var_s_loc[var+'_sd'].values[0:57], var_y_loc[var+'_sd'].values[57:])\n",
    " \n",
    "    # otherwise we try to use the annual sd for entire array\n",
    "    # but check whether the annual data has enough observations until depth of 1500 m (level 57)\n",
    "    elif all(i >= 5 for i in var_y_loc[var+'_dd'].values[0:57]):\n",
    "        print('sd',var, 'from annual data')\n",
    "        var_sd = var_y_loc[var+'_sd'].values\n",
    "\n",
    "    # this will mainly apply to the oxygen data\n",
    "    else:\n",
    "        print('sd',var, 'this does not work, use the other approach')\n",
    "     \n",
    "    # all unvalid sd values (with dd < 5) are nan\n",
    "    var_sd = np.where(var_y_loc[var+'_dd'].values < 5, np.nan, var_sd)\n",
    "   \n",
    "    return var_sd\n",
    "\n",
    "\n",
    "\n",
    "def interp_sd_for_doxy(lat, lon):\n",
    "    # get area\n",
    "    df_o_sel = select_area(df_o_d_enough,lat,lon)\n",
    "\n",
    "    # make dataframe \n",
    "    df_sel = pd.DataFrame(data={'Depth': depths})\n",
    "    name_LL = []\n",
    "    for lats in df_o_sel.lat.unique():\n",
    "        for lons in df_o_sel.lon.unique():\n",
    "\n",
    "            o_loc = o.sel(lat=lats, lon=lons, method=\"nearest\")\n",
    "\n",
    "            name_LL.append(str(lats)+str(lons))\n",
    "            df_sel[str('dd_'+str(lats)+str(lons))] = o_loc.o_dd.values\n",
    "            df_sel[str('sd_'+str(lats)+str(lons))] = o_loc.o_sd.values\n",
    "\n",
    "    # make values nan if dd < 5\n",
    "    for n in name_LL:    \n",
    "        df_sel['sd_'+n] = np.where(df_sel['dd_'+n] < 5, np.nan, df_sel['sd_'+n])\n",
    "\n",
    "    # make new column with average of sd columns\n",
    "    df_sel['sd_avg'] = df_sel[df_sel.columns[pd.Series(df_sel.columns).str.startswith('sd')]].mean(axis=1)\n",
    "\n",
    "    # fill all nan values with last valid sd\n",
    "    df_sel['sd_avg'] = df_sel['sd_avg'].fillna(method='ffill')\n",
    "    \n",
    "    # get the interpolator\n",
    "    interp = PchipInterpolator(depths, df_sel['sd_avg'].values, extrapolate=True)\n",
    "    print('got oxygen area')\n",
    "    \n",
    "    return interp\n",
    " \n",
    "    \n",
    "\n",
    "def select_area(df,lat,lon):    \n",
    "    df_loc = df[(df.lon > lon-10) & (df.lon < lon+10) & \n",
    "                    (df.lat > lat-10) & (df.lat < lat+10)]    \n",
    "    return df_loc\n",
    "    \n",
    "\n",
    "def forward_fill(arr):\n",
    "    d = pd.DataFrame(arr)\n",
    "    d = d.fillna(method='ffill')\n",
    "    return np.array(d[0].values)\n",
    "\n",
    "\n",
    "def get_interpolators(var, lat, lon, seas, datatype='an'):        \n",
    "    if datatype == 'sd':\n",
    "        var_arr = import_var_sd(var, lat, lon, seas)\n",
    "    else: \n",
    "        var_arr = import_var_an(var, lat, lon, seas)\n",
    "    \n",
    "    # get rid of nan values\n",
    "    var_arr = forward_fill(var_arr)\n",
    "    \n",
    "    # make interpolator    \n",
    "    var_interp = PchipInterpolator(depths, var_arr, extrapolate=True)\n",
    "    \n",
    "    return var_interp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753c42e",
   "metadata": {},
   "source": [
    "## add data to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903060a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P66'] 18.8 -168.5 00\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['B67'] 18.82 -168.51 00\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['M77'] 23.3 -70.5 13\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['M77'] 23.1 -65.2 15\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['M77'] 22.8 -55.1 15\n",
      "sd t from annual data\n",
      "sd s from annual data\n",
      "got oxygen area\n",
      "['M77'] 25.9 -60.3 15\n",
      "sd t from annual data\n",
      "sd s from annual data\n",
      "got oxygen area\n",
      "['HE78'] 32.37 -55.0 16\n",
      "sd t from annual data\n",
      "sd s from annual data\n",
      "got oxygen area\n",
      "['T81'] 4.0 -82.0 15\n",
      "sd t from annual data\n",
      "sd s from annual data\n",
      "got oxygen area\n",
      "['M82'] 0.0 -152.2 00\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['T97'] 22.75 -158.0 13\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['T97'] 22.75 -158.0 14\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['F08'] 29.98 175.0 15\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n",
      "['N19' 'D19' 'S22'] 27.75 -155.283 15\n",
      "sd t from annual data\n",
      "sd s from annual data\n",
      "got oxygen area\n",
      "['N19' 'D19' 'S22'] 35.267 -150.983 15\n",
      "sd t from annual data\n",
      "sd s from annual data\n",
      "got oxygen area\n",
      "['N19' 'D19' 'S22'] 41.716 -148.3 15\n",
      "sd t from annual data\n",
      "sd s from annual data\n",
      "got oxygen area\n",
      "['N19' 'D19' 'S22'] 49.683 -155.28 15\n",
      "sd t from seasonal + annual data\n",
      "sd s from seasonal + annual data\n",
      "got oxygen area\n"
     ]
    }
   ],
   "source": [
    "# prepare oxygen dataset\n",
    "o = xr.open_dataset(path_woa+\"woa18_all_o00_01.nc\", decode_times=False).isel(time=0, drop=True)\n",
    "# make df of data at certain depth\n",
    "o_d = o.isel(depth = 56)\n",
    "df_o_d = o_d.to_dataframe().reset_index()\n",
    "\n",
    "# only keep rows were I have enough measurements\n",
    "df_o_d_enough = df_o_d[df_o_d.o_dd >= 5]\n",
    "\n",
    "#ignore performance warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "# Location\n",
    "for lat, lon in zip(df[\"Latitude\"].unique(), df[\"Longitude\"].unique()):\n",
    "    locat = (df[\"Latitude\"] == lat) & (df[\"Longitude\"] == lon)\n",
    "        \n",
    "    for month in df[locat]['Month'].unique():\n",
    "        # no month given, annual average instead of a season\n",
    "        if np.isnan(month):\n",
    "            seas = '00'\n",
    "        else:\n",
    "            seas = seasons[month] \n",
    "            \n",
    "        print(df[(locat)]['Source_abbrev'].unique(), lat, lon, seas)\n",
    "            \n",
    "        t_interp = get_interpolators('t', lat, lon, seas) \n",
    "        df.loc[(locat),[\"Temp_woa\"]] = t_interp(df[locat]['Depth'])\n",
    "        t_sd_interp = get_interpolators('t', lat, lon, seas, 'sd') \n",
    "        df.loc[(locat),[\"Temp_SD_woa\"]] = t_sd_interp(df[locat]['Depth'])\n",
    "        \n",
    "        s_interp = get_interpolators('s', lat, lon, seas)                \n",
    "        df.loc[(locat),[\"Sal_woa\"]] = s_interp(df[locat]['Depth'])        \n",
    "        s_sd_interp = get_interpolators('s', lat, lon, seas, 'sd')                \n",
    "        df.loc[(locat),[\"Sal_SD_woa\"]] = s_sd_interp(df[locat]['Depth'])\n",
    "        \n",
    "        o_interp = get_interpolators('o', lat, lon, seas)                \n",
    "        df.loc[(locat),[\"Doxy_woa\"]] = o_interp(df[locat]['Depth'])\n",
    "        \n",
    "        o_interp = interp_sd_for_doxy(lat, lon)                \n",
    "        df.loc[(locat),[\"Doxy_SD_woa\"]] = o_interp(df[locat]['Depth'])\n",
    "                \n",
    "        \n",
    "        # currently not adding standard deviation\n",
    "        p_interp = get_interpolators('p', lat, lon, seas)                \n",
    "        df.loc[(locat),[\"PO4_woa\"]] = p_interp(df[locat]['Depth'])\n",
    "        \n",
    "        i_interp = get_interpolators('i', lat, lon, seas)                \n",
    "        df.loc[(locat),[\"SiOH4_woa\"]] = i_interp(df[locat]['Depth'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79495c",
   "metadata": {},
   "source": [
    "## Save data \n",
    "- in normal csv\n",
    "- in csv without headers for the Matlab stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c604f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Doxy_SD_woa'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01cfddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Depth', 'Source', 'Source_abbrev', 'Latitude', 'Longitude', 'Sample',\n",
       "       'Material', 'Rate_sa', 'Rate_error_sa', 'Organics', 'Device',\n",
       "       'Deployment_d', 'Biogenic', 'Year', 'Comments', 'Mesh', 'Rate_mass',\n",
       "       'Month', 'Size', 'Fragmentation_pct', 'Rate_error_mass', 'Temp_CDisk4',\n",
       "       'pH_CDisk4_T25', 'Salinity_CDisk4', 'TA_CDisk4', 'DIC_CDisk4_calc13',\n",
       "       'Oca_CDisk4_calc13', 'Oar_CDisk4_calc13', 'Omega_CDisk4_calc13',\n",
       "       'Pressure', 'Temp_woa', 'Temp_SD_woa', 'Sal_woa', 'Sal_SD_woa',\n",
       "       'Doxy_woa', 'Doxy_SD_woa', 'PO4_woa', 'SiOH4_woa'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da995d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/in_situ_rates_compiled_withWOA.csv\", index=False)\n",
    "\n",
    "#save another version just with the stuff I need to do CANYON-B\n",
    "df_canyonb = df[[\"Latitude\", \"Longitude\", \"Depth\", \"Pressure\", \n",
    "                 \"Temp_woa\", \"Sal_woa\", \"Doxy_woa\", \"Year\", \"Month\"]].copy()\n",
    "#if I don't know the month, I put January in\n",
    "df_canyonb.loc[pd.isna(df_canyonb.Month), \"Month\"] = 1\n",
    "df_canyonb.to_csv(\"data/in_situ_rates_compiled_withWOA_forCANYONB.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e3d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
